{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7332fbf8-e307-4892-beba-026235193ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e06b32-3558-4cdf-9ef4-0fc3635fae9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Application Example: Robot Welding\n",
    "\n",
    "A good example where such motion controllers are needed is robotic welding. This section will briefly show the combination of the newly derived motion controller and the newly derived interpolation algorithm and an example  via the developed simulation environment. To incorperate the extra redundancy given by the symmetry around the welding tool, the cobot kinematics are extended by an extra degree of freedom. This joint is then used virtually as an extra DoF for optimization. Modern welding applications with cobots are often intuitively set up with a hand-guiding mode. Here, the welding gun is positioned in the key poses on the welding part by the user, and motion primitives are chosen for interpolation between these key poses. \n",
    "\n",
    "A more modern approach developed by Neura Robotics is that the welding part and the welding seams are predefined by the user, uploaded in the GUI as virtual model. With the virtual model and the advanced object detection of Maira, the position and orientation of the welding part, which can be arbitrarily placed in some predefined area, can be detected. The parts are then welded autonomously. The attached video will showcase this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d9b36b-e538-4247-b4dc-0734c28236c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"1100\" height=\"700\" controls>\n",
       "  <source src=\".\\Resources\\maira_welding.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"1100\" height=\"700\" controls>\n",
    "  <source src=\".\\Resources\\maira_welding.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf905e7-2be2-4cd9-9d7b-69937aedd139",
   "metadata": {},
   "source": [
    "In both cases, key poses as a set of unit dual quaternions $\\mathbb{X} = [\\underline{\\xi}_1, \\underline{\\xi}_2, \\dots, \\underline{\\xi}_n]$ are intrinsically defined, either via the forward kinematics of the robot when using the hand guiding mode, or via the object detection algorithm and the predefined key poses in the given CAD file. In terms of this showcase, the key poses are defined manually. The application of dual quaternions in robot welding is especially interesting as it allows to discern between short and long-path interpolation of orientation. This is beneficial as non-expert users often struggle with conceptualizing a short path orientation interpolation, as would be needed for a homogenous transformation matrix-based approach. Here, no double cover of $\\mathcal{SE}(3)$ is given, which forces the roboticists to fall back on strict short-path interpolation, even if the intention by the user was different during the setup of the robotic trajectory.\n",
    "\n",
    "The following, manually defined key poses $\\mathbb{X}$ define different sets of poses which are either used for linear, or circular interpolation by leveraging the interpolation algorithm of <a href=\"./3.4_dual_quaternion_interpolation.ipynb\">Chapter 3.4</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd8dea8-d80c-4e1e-93ff-6287adc6053c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# orientations for first trajectory\n",
    "quat0 = Quaternion.fromAxisAngle(np.pi*1.25, np.array([0,1,0]))\n",
    "quat1 = Quaternion.fromAxisAngle(np.pi*0.5, np.array([0,0,1]))\n",
    "quat2 = Quaternion.fromAxisAngle(np.pi, np.array([0,0,1]))\n",
    "quat3 = Quaternion.fromAxisAngle(np.pi*1.5, np.array([0,0,1]))\n",
    "\n",
    "# first line segments\n",
    "x1 = DualQuaternion.fromQuatPos(quat0, np.array([1.2, -0.3, 0.1]))\n",
    "x2 = DualQuaternion.fromQuatPos(quat0, np.array([1.2, 0.1, 0.1]))\n",
    "x3 = DualQuaternion.fromQuatPos(quat1*quat0, np.array([1.2, 0.1, 0.1]))\n",
    "x4 = DualQuaternion.fromQuatPos(quat1*quat0, np.array([0.950, 0.1, 0.1]))\n",
    "x5 = DualQuaternion.fromQuatPos(quat2*quat0, np.array([0.950, 0.1, 0.1]))\n",
    "x6 = DualQuaternion.fromQuatPos(quat2*quat0, np.array([0.950, -0.3, 0.1]))\n",
    "x7 = DualQuaternion.fromQuatPos(quat3*quat0, np.array([0.950, -0.3, 0.1]))\n",
    "x8 = DualQuaternion.fromQuatPos(quat3*quat0, np.array([1.2, -0.3, 0.1]))\n",
    "\n",
    "# orientations for second trajectory\n",
    "quat4 = Quaternion.fromAxisAngle(np.pi*1.5, np.array([0,1,0]))\n",
    "quat5 = Quaternion.fromAxisAngle(np.pi*0.25, np.array([0,0,1])) \n",
    "quat6 = Quaternion.fromAxisAngle(-np.pi*0.5, np.array([0,0,1])) \n",
    "quat7 = Quaternion.fromAxisAngle(-np.pi, np.array([0,0,1])) \n",
    "\n",
    "# second line segments\n",
    "x9 = DualQuaternion.fromQuatPos(quat4, np.array([0.850, 0.0, 0.1]))\n",
    "x10 = DualQuaternion.fromQuatPos(quat4, np.array([0.850, 0.0, 0.4]))\n",
    "x11 = DualQuaternion.fromQuatPos(quat5*quat0, np.array([0.850, 0.0, 0.4]))\n",
    "\n",
    "#first arc segments\n",
    "x12 = DualQuaternion.fromQuatPos(quat0, np.array([0.90, -0.05, 0.4]))\n",
    "x13 = DualQuaternion.fromQuatPos(quat6*quat0, np.array([0.850, -0.1, 0.4]))\n",
    "x14 = DualQuaternion.fromQuatPos(quat7*quat0, np.array([0.80, -0.05, 0.4]))\n",
    "\n",
    "# third line segments\n",
    "x15 = DualQuaternion.fromQuatPos(quat7*quat0, np.array([0.80, 0.3, 0.4]))\n",
    "x16 = DualQuaternion.fromQuatPos(quat6*quat0, np.array([0.80, 0.3, 0.4]))\n",
    "x17 = DualQuaternion.fromQuatPos(quat6*quat0, np.array([0.60, 0.3, 0.4]))\n",
    "x18 = DualQuaternion.fromQuatPos(quat6*quat0, np.array([0.60, 0.0, 0.6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90344c8a-f836-4107-b7b2-89ade01a08c6",
   "metadata": {},
   "source": [
    "For an intuitive setup, the required unit dual quaternions are defined as orientation unit quaternion and desired position, respectively.\n",
    "\n",
    "Given the desired motion limits and the desired cartesian velocity for the welding task as defined in the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf21917-4f75-4efa-abc5-5e150f9cf583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the acceleration and jerk limits\n",
    "a_cart_max = 3\n",
    "j_cart_max = 30\n",
    "a_ang_max = 3\n",
    "j_ang_max = 30\n",
    "\n",
    "# define desired cartesian velocites and maximum angular velocity\n",
    "des_cart_vel = 0.03\n",
    "max_ang_vel = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be07616-7830-4be3-995e-a81dc0ddc09b",
   "metadata": {},
   "source": [
    "The desired trajectories from the DQQB interpolation algorithm are then defined as known from <a href=\"./3.4_dual_quaternion_interpolation.ipynb\">Chapter 3.4</a>. For this, we define the required sets of unit dual quaternions $\\mathbb{X}_{line1}$, $\\mathbb{X}_{line2}$, $\\mathbb{X}_{arc2}$ and $\\mathbb{X}_{line3}$. These sets are used to define two trajectories. The first trajectory moves along the unit dual quaternion set $\\mathbb{X}_{line1}$, defined by the LineGenerator. The second trajectory concatenates the last three unit dual quaternion sets to produce a mix of MoveLinear and MoveCircle, which results in a MoveComposite motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25298eaf-fbb0-4ed6-9bcd-2d91d763bebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  1\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "iteration:  2\n",
      "iteration:  3\n",
      "iteration:  4\n",
      "iteration:  5\n",
      "iteration:  6\n",
      "iteration:  7\n",
      "iteration:  8\n",
      "iteration:  9\n",
      "iteration:  10\n",
      "iteration:  1\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "acceleration limit violated!\n",
      "blendphases overlapped\n",
      "iteration:  2\n",
      "blendphases overlapped\n",
      "iteration:  3\n",
      "iteration:  4\n",
      "iteration:  5\n",
      "iteration:  6\n",
      "iteration:  7\n",
      "iteration:  8\n",
      "iteration:  9\n",
      "iteration:  10\n"
     ]
    }
   ],
   "source": [
    "# assign dual quaternions to lists\n",
    "line1_DQ_list = [x1, x2, x3, x4, x5, x6]\n",
    "line2_DQ_list = [x9, x10, x11]\n",
    "arc2_DQ_list = [x11, x12, x13, x14]\n",
    "line3_DQ_list = [x14, x15, x16, x17]\n",
    "\n",
    "# initialize the DQQBTrajectoryGenerator\n",
    "trajectory1 = DQQBTrajectoryGenerator()\n",
    "trajectory2 = DQQBTrajectoryGenerator()\n",
    "\n",
    "# initialize line and arc generators\n",
    "line_generator = LineGenerator()\n",
    "arc_generator = ArcGenerator()\n",
    "\n",
    "# generate segments\n",
    "line_segments1 = line_generator.generateSegments(line1_DQ_list, des_cart_vel, max_ang_vel)\n",
    "line_segments2 = line_generator.generateSegments(line2_DQ_list, des_cart_vel, max_ang_vel)\n",
    "arc_segments2 = arc_generator.generateSegments(arc2_DQ_list, des_cart_vel, max_ang_vel)\n",
    "line_segments3 = line_generator.generateSegments(line3_DQ_list, des_cart_vel, max_ang_vel)\n",
    "\n",
    "segments2 = line_segments2 + arc_segments2 + line_segments3\n",
    "\n",
    "trajectory1.generateDynamicTrajectory(line_segments1, a_cart_max, j_cart_max, a_ang_max, j_ang_max)\n",
    "trajectory2.generateDynamicTrajectory(segments2, a_cart_max, j_cart_max, a_ang_max, j_ang_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a196816-8f5e-493a-bfc2-1627dded21f7",
   "metadata": {},
   "source": [
    "Both trajectories successfully ran the offline optimization, as seen acceleration limits were violated and blend phases overlapped. The entire robot motion is set up as a concatenation of <i>tasks</i>. These tasks also include MoveJoint and MoveLinear commands, which connect the continous paths from the DQQB interpolation. The robot type can be defined as either \"weld\" or \"extended\" defining MAiRA as a 7 or 8 DoF robot, depending on whether the virtual joint should be activated to enable another DoF or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfeb3c2e-af8a-4d2c-83d3-efe76a3c391f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "robot_type = \"weld\"\n",
    "#robot_type = \"extended\"\n",
    "\n",
    "fk = ForwardKinematics(robot_type)\n",
    "\n",
    "q1 = np.array([deg2rad(-20), deg2rad(40), 0, deg2rad(70), 0, deg2rad(40), 0])\n",
    "q2 = np.array([deg2rad(10), deg2rad(30), 0, deg2rad(90), 0, deg2rad(40), 0])\n",
    "\n",
    "task_list = np.array([MoveJoint(q1, 2), MoveLinear(fk.getFK(q1), x1, 1), \n",
    "                      MoveTrajectory(trajectory1), MoveLinear(x6, fk.getFK(q1), 3),\n",
    "                      MoveJoint(q2, 4), MoveLinear(fk.getFK(q2), x9, 2),\n",
    "                      MoveTrajectory(trajectory2), MoveLinear(x17, x18, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c8a13-e506-4764-a1a5-e9e9642d81cd",
   "metadata": {},
   "source": [
    "Running the last code block sets up the simulation environment and starts the simulated welding process. The motion controller chosen can be \"classic\" or \"qp\", where either the classic formulation via pseudo inversion of the Jacobian with nullspace projection of the manipulability gradient is shown, or the developed predictive motion controller from <a href=\"./3.3_predictive_differential_kinematics.ipynb\">Chapter 3.3</a>. The demo shown here shows the proposed QP-based motion controller. The reader is encouraged to test the \"classic\" motion controller and the \"extended\" robot type, as well as their perturbations with the current settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "032a46d9-f632-406e-ae15-fea4abd45f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_method = \"qp\"\n",
    "#control_method = \"classic\"\n",
    "\n",
    "sim = Simulation(task_list, robot_type, method = control_method)\n",
    "\n",
    "sim.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a06b56-df53-4173-b9e9-f03b8da02375",
   "metadata": {
    "tags": []
   },
   "source": [
    "As seen in the Simulation environment, the proposed method and interpolation scheme is capable of complex path interpolation and the ability to smoothly follow this trajectory in an online fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99b70f-81d1-46aa-832c-ee0d460cc44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
